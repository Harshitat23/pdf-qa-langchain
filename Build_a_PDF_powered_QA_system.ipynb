{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Build a PDF-powered QA system using embeddings + LangChain."
      ],
      "metadata": {
        "id": "ZCwhXQCkuS6y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM3eL8kGqcYl"
      },
      "outputs": [],
      "source": [
        "import PyPDF2  # Library for reading and extracting text from PDF files\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS  # Vector store for storing and searching text embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings  # Generates embeddings using HuggingFace models\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import RetrievalQA\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "except ImportError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "ymVLgUyRt6Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFQASystem:\n",
        "    def __init__(self, pdf_path, chunk_size=1000, chunk_overlap=200, groq_api_key=None):\n",
        "        \"\"\"\n",
        "        Initialize the PDF QA system.\n",
        "\n",
        "        Args:\n",
        "            pdf_path (str): Path to the PDF file\n",
        "            chunk_size (int): Size of text chunks for processing\n",
        "            chunk_overlap (int): Overlap between chunks\n",
        "            groq_api_key (str, optional): Groq API key, if not using environment variable\n",
        "        \"\"\"\n",
        "        self.pdf_path = pdf_path\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.groq_api_key = groq_api_key\n",
        "        self.vector_store = None\n",
        "        self.qa_chain = None\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "\n",
        "        # Initialize text splitter\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            length_function=len\n",
        "        )\n",
        "\n",
        "    def extract_text_from_pdf(self):\n",
        "        \"\"\"Extract text from PDF file.\"\"\"\n",
        "        try:\n",
        "            with open(self.pdf_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text()\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading PDF: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_vector_store(self):\n",
        "        \"\"\"Create vector store from PDF text.\"\"\"\n",
        "        # Extract text\n",
        "        text = self.extract_text_from_pdf()\n",
        "        if not text:\n",
        "            return False\n",
        "\n",
        "        # Split text into chunks\n",
        "        texts = self.text_splitter.split_text(text)\n",
        "\n",
        "        # Create vector store\n",
        "        self.vector_store = FAISS.from_texts(\n",
        "            texts,\n",
        "            self.embeddings\n",
        "        )\n",
        "        return True\n",
        "\n",
        "    def initialize_qa_chain(self):\n",
        "        \"\"\"Initialize the QA chain with Groq's ChatGroq model.\"\"\"\n",
        "        if self.vector_store is None:\n",
        "            print(\"Vector store not initialized. Run create_vector_store first.\")\n",
        "            return False\n",
        "\n",
        "        # Initialize Groq LLM\n",
        "        try\n",
        "            api_key = self.groq_api_key or os.environ.get(\"GROQ_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"GROQ_API_KEY not found. Set the environment variable or pass groq_api_key to PDFQASystem.\")\n",
        "\n",
        "            llm = ChatGroq(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                temperature=0,\n",
        "                max_tokens=None,\n",
        "                groq_api_key=api_key\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing Groq LLM: {e}\")\n",
        "            return False\n",
        "\n",
        "        # Create retrieval QA chain\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=self.vector_store.as_retriever(\n",
        "                search_kwargs={\"k\": 3}  # Return top 3 relevant chunks\n",
        "            )\n",
        "        )\n",
        "        return True\n",
        "\n",
        "    def query(self, question):\n",
        "        \"\"\"Query the system with a question.\"\"\"\n",
        "        if self.qa_chain is None:\n",
        "            print(\"QA chain not initialized. Run initialize_qa_chain first.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            response = self.qa_chain.run(question)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing query: {e}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "j8rgN9mQtbtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Example usage\n",
        "    pdf_path = \"/content/Machine Translation (1).pdf\"\n",
        "    groq_api_key = None\n",
        "\n",
        "    # Initialize QA system\n",
        "    qa_system = PDFQASystem(pdf_path, groq_api_key=groq_api_key)\n",
        "\n",
        "    # Create vector store\n",
        "    if not qa_system.create_vector_store():\n",
        "        print(\"Failed to create vector store\")\n",
        "        return\n",
        "\n",
        "    # Initialize QA chain\n",
        "    if not qa_system.initialize_qa_chain():\n",
        "        print(\"Failed to initialize QA chain\")\n",
        "        return\n",
        "\n",
        "    questions = [\n",
        "        \"What is the main topic of the document?\",\n",
        "        \"Summarize the key points.\"\n",
        "    ]\n",
        "\n",
        "    for question in questions:\n",
        "        response = qa_system.query(question)\n",
        "        if response:\n",
        "            print(f\"\\nQ: {question}\")\n",
        "            print(f\"A: {response}\")"
      ],
      "metadata": {
        "id": "HtO0AUq8uBiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvy3MmAHuGmV",
        "outputId": "afce1805-b149-49ef-fd24-e2258bba6def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-1362082139.py:101: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = self.qa_chain.run(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What is the main topic of the document?\n",
            "A: The main topic of the document is Machine Translation (MT).\n",
            "\n",
            "Q: Summarize the key points.\n",
            "A: Here are the key points summarized:\n",
            "\n",
            "**Types of Machine Translation:**\n",
            "\n",
            "1. **Rule-based Machine Translation**: Uses built-in linguistic rules and bilingual dictionaries to translate specific content accurately.\n",
            "2. **Statistical Machine Translation**: Uses machine learning to analyze large amounts of human translations and make predictions based on statistical likelihood.\n",
            "3. **Neural Machine Translation**: Uses artificial intelligence and neural networks to learn languages and improve translation accuracy.\n",
            "\n",
            "**Machine Translation Process:**\n",
            "\n",
            "1. Input text is prepared and filtered.\n",
            "2. The system is trained using examples of texts in multiple languages and their translations.\n",
            "3. The system learns patterns and probabilities of word and phrase translations.\n",
            "4. The system generates a translated version of the input text.\n",
            "5. Additional adjustments may be made to refine the translation.\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "* Statistical methods require large amounts of training data for accurate translations.\n",
            "* Neural Machine Translation can learn complex patterns and dependencies in language data.\n",
            "* Machine translation can go beyond simple word-to-word translation to communicate the full meaning of the original text.\n"
          ]
        }
      ]
    }
  ]
}